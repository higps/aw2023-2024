{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Books!\n",
    "### Working with different file formats and APIs\n",
    "\n",
    "- In this task you will ingest data from different sources (XML, JSON, API)\n",
    "- You will combine the data into one table and write this to a single CSV\n",
    "- This requires you to handle different file formats and wrangle them to an appropriate format that can be represented as a table\n",
    "\n",
    "#### ETL Structure\n",
    "- Create a folder structure to structure your files\n",
    "- `Raw` - The raw JSON and XML file\n",
    "- `Bronze` - Your files represented as CSV files\n",
    "- `Silver` - A single CSV where you've joined all data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Imports\n",
    "import json\n",
    "import csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1 - Ingest JSON of Books \n",
    "- Read the JSON file to get details of 30 books\n",
    "- Perform the appropriate wrangling and store it as a CSV in your `Bronze` folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Code\n",
    "json_file_path = \"Raw/books_multi.json\"\n",
    "csv_file_out = \"Bronze/books.csv\"\n",
    "# Initialize an empty list to store the parsed JSON objects\n",
    "data = []\n",
    "\n",
    "with open(json_file_path, 'r') as json_file:\n",
    "    # Read the lines from the file\n",
    "    lines = json_file.readlines()\n",
    "\n",
    "    # Iterate through each line and load the JSON data\n",
    "    for line in lines:\n",
    "        # Load each line as a separate JSON object\n",
    "        json_data = json.loads(line)\n",
    "        \n",
    "        # Append the loaded JSON object to the list\n",
    "        data.append(json_data)\n",
    "\n",
    "with open(csv_file_out, 'w',newline='') as csv_file:\n",
    "# Write header    \n",
    "    # Create a CSV writer\n",
    "    field_names = list(data[0].keys())\n",
    "    csv_writer = csv.DictWriter(csv_file, fieldnames=field_names)\n",
    "\n",
    "    # Write the header to the CSV file\n",
    "    csv_writer.writeheader()\n",
    "\n",
    "    # Write the data to the CSV file\n",
    "    csv_writer.writerows(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ingest XML of Authors: \n",
    "- Parse the XML file for information on the authors\n",
    "- Perform the appropriate wrangling and store it as a CSV in your `Bronze` folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['John Doe', '1000000001'], ['John Doe', '1000000014'], ['John Doe', '1000000027'], ['Jane Smith', '1000000002'], ['Jane Smith', '1000000015'], ['Emily Johnson', '1000000003'], ['Michael Brown', '1000000004'], ['Michael Brown', '1000000016'], ['Sarah Davis', '1000000005'], ['William Miller', '1000000006'], ['William Miller', '1000000017'], ['William Miller', '1000000028'], ['Elizabeth Wilson', '1000000007'], ['Elizabeth Wilson', '1000000018'], ['David Moore', '1000000008'], ['Jennifer Taylor', '1000000009'], ['Jennifer Taylor', '1000000019'], ['Jennifer Taylor', '1000000029'], ['Richard Anderson', '1000000010'], ['Patricia Jackson', '1000000011'], ['Patricia Jackson', '1000000020'], ['Christopher Harris', '1000000012'], ['Christopher Harris', '1000000021'], ['Christopher Harris', '1000000030']]\n"
     ]
    }
   ],
   "source": [
    "## Code needs to be modified to be in a better format for CSV\n",
    "from lxml import etree\n",
    "xml_in_path = \"Raw/authors.xml\"\n",
    "xml_out_path = 'Bronze/authors.csv'\n",
    "book_and_author_list = []\n",
    "books = []\n",
    "with open(xml_in_path, 'r', newline='') as xml_file:\n",
    "    # Parse the XML content\n",
    "    tree = etree.parse(xml_file)\n",
    "    root = tree.getroot()\n",
    "    # Now you can work with the XML data using the 'root' element\n",
    "    # For example, you can iterate through elements\n",
    "    pog_dict = {}\n",
    "    for author in root.findall('author'):\n",
    "        author_name = author.find('name').text\n",
    "\n",
    "        # Assuming the tag for books is 'books', and the tag for book ISBN is 'book_isbn'\n",
    "        # books = [book.text for book in author.find('books').findall('book_isbn')]\n",
    "        \n",
    "        # Add to the dictionary if the author has books\n",
    "        # if books:\n",
    "        #     pog_dict[author_name] = books\n",
    "\n",
    "        # Write each book and author pair as two elements in a list for simpler CSV creation\n",
    "        for book in author.find('books').findall('book_isbn'):\n",
    "            book_and_author_list.append([author_name, book.text])\n",
    "            books.append(book.text)\n",
    "\n",
    "print(book_and_author_list)\n",
    "    # print(pog_dict)\n",
    "    # print(list(pog_dict.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(xml_out_path, 'w', newline='') as xml_file_out:\n",
    "    field_names = list(pog_dict.keys())\n",
    "    csv_writer = csv.writer(xml_file_out)\n",
    "\n",
    "    # Write the header to the CSV file\n",
    "    header = ['author', 'isbn']\n",
    "    \n",
    "    csv_writer.writerow(header)\n",
    "\n",
    "    # Write the data to the CSV file\n",
    "    csv_writer.writerows(book_and_author_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OLD CODE FOR DICTIONARY SETUP\n",
    "# with open(xml_out_path, 'w', newline='') as xml_file_out:\n",
    "#     field_names = list(pog_dict.keys())\n",
    "#     csv_writer = csv.DictWriter(xml_file_out, fieldnames=field_names)\n",
    "\n",
    "#     # Write the header to the CSV file\n",
    "#     csv_writer.writeheader()\n",
    "\n",
    "#     # Write the data to the CSV file\n",
    "#     csv_writer.writerow(pog_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fetch Ratings from API: \n",
    "- For each book, use the Random Numbers API to fetch 10 ratings (1 to 5)\n",
    "- The endpoint you'll use is: \"http://www.randomnumberapi.com/api/v1.0/random?min=1&max=5&count=10\"\n",
    "- Store the ratings in a CSV in your `Bronze` folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "# flatten out book_list to a pure list of books with no duplicates\n",
    "# this is where book_list is a combined list with authors and books  , no need to do this when we have a books list with only the book ids\n",
    "# flattened_list = []\n",
    "# seen_books = set()\n",
    "\n",
    "# for sublist in book_list:\n",
    "#     for book in sublist:\n",
    "#         if book not in seen_books:\n",
    "#             flattened_list.append(book)\n",
    "#             seen_books.add(book)\n",
    "\n",
    "# # Print the result\n",
    "# print(flattened_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Code\n",
    "min = 1\n",
    "max = 5\n",
    "count = 10\n",
    "def get_ratings():\n",
    "    response = requests.get(f\"https://www.randomnumberapi.com/api/v1.0/random?min={min}&max={max}&count={count}\")\n",
    "\n",
    "    if not response.ok:\n",
    "        print(\"Request was bad!\")\n",
    "        return False\n",
    "    # If we use the response.json() function, we get a dict back!\n",
    "    type(response.json())\n",
    "\n",
    "    json_response = response.json()\n",
    "    return json_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get the ratings\n",
    "\n",
    "# print(get_ratings())\n",
    "book_ratings = {}\n",
    "for book in books:\n",
    "    book_ratings[book] = get_ratings()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'1000000001': [4, 4, 3, 3, 2, 1, 4, 2, 2, 2], '1000000014': [3, 2, 1, 3, 3, 3, 1, 2, 1, 1], '1000000027': [4, 3, 4, 4, 3, 4, 1, 2, 2, 3], '1000000002': [1, 1, 1, 3, 3, 4, 4, 1, 1, 4], '1000000015': [4, 2, 1, 2, 3, 3, 3, 2, 2, 4], '1000000003': [3, 1, 3, 4, 2, 2, 3, 2, 4, 2], '1000000004': [3, 4, 4, 1, 1, 2, 3, 1, 2, 2], '1000000016': [1, 1, 3, 4, 1, 1, 4, 4, 1, 2], '1000000005': [2, 3, 4, 4, 3, 1, 3, 3, 2, 4], '1000000006': [2, 3, 1, 2, 1, 3, 1, 1, 2, 3], '1000000017': [2, 4, 4, 1, 1, 2, 1, 4, 3, 1], '1000000028': [4, 4, 2, 2, 2, 2, 1, 3, 2, 3], '1000000007': [4, 4, 1, 1, 2, 2, 1, 1, 4, 1], '1000000018': [1, 3, 3, 2, 2, 2, 3, 3, 3, 3], '1000000008': [2, 1, 1, 4, 2, 3, 2, 4, 2, 3], '1000000009': [3, 3, 2, 3, 2, 3, 1, 2, 3, 1], '1000000019': [2, 1, 1, 4, 1, 4, 3, 1, 3, 1], '1000000029': [3, 2, 2, 4, 3, 4, 4, 3, 4, 3], '1000000010': [3, 2, 2, 4, 3, 2, 2, 4, 2, 4], '1000000011': [2, 1, 4, 3, 3, 4, 1, 1, 4, 4], '1000000020': [1, 4, 3, 4, 4, 3, 2, 4, 2, 3], '1000000012': [1, 1, 2, 3, 2, 1, 4, 4, 2, 3], '1000000021': [3, 1, 1, 4, 2, 4, 2, 2, 2, 4], '1000000030': [4, 4, 2, 3, 4, 2, 2, 3, 1, 1]}\n"
     ]
    }
   ],
   "source": [
    "print(book_ratings)\n",
    "book_ratings_path = 'Bronze/book_ratings.csv'\n",
    "with open(book_ratings_path, 'w', newline='') as book_csv_out:\n",
    "\n",
    "    csv_writer = csv.writer(book_csv_out)\n",
    "\n",
    "    # Write the header to the CSV file\n",
    "    csv_writer.writerow([\"book_isbn\", \"rating_list\"])\n",
    "\n",
    "    # Write the data to the CSV file\n",
    "    for isbn, ratings in book_ratings.items():\n",
    "        csv_writer.writerow([isbn, ratings])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'1000000001': ['Data Structures in Python', '2020'], '1000000002': ['Introduction to ETL Processes', '2019'], '1000000003': ['APIs for Beginners', '2021'], '1000000004': ['Machine Learning Fundamentals', '2018'], '1000000005': ['Database Management Essentials', '2022'], '1000000006': ['Cloud Computing Basics', '2020'], '1000000007': ['The Art of Data Science', '2019'], '1000000008': ['Python for Data Analysis', '2021'], '1000000009': ['Algorithms Unlocked', '2020'], '1000000010': ['Web Development with JavaScript', '2018'], '1000000011': ['Introduction to IoT', '2022'], '1000000012': ['Networking for Beginners', '2019'], '1000000013': ['Cybersecurity Fundamentals', '2020'], '1000000014': ['Big Data Analysis', '2021'], '1000000015': ['Programming in Java', '2018'], '1000000016': ['HTML and CSS Design', '2022'], '1000000017': ['Software Testing Techniques', '2019'], '1000000018': ['Blockchain Basics', '2020'], '1000000019': ['Artificial Intelligence Concepts', '2021'], '1000000020': ['Quantum Computing 101', '2018'], '1000000021': ['Virtual Reality in the Modern World', '2022'], '1000000022': ['Ethical Hacking for Beginners', '2019'], '1000000023': ['Augmented Reality: A Comprehensive Guide', '2020'], '1000000024': ['Understanding Cryptography', '2021'], '1000000025': ['Exploring Data Visualization', '2018'], '1000000026': ['Introduction to Game Development', '2022'], '1000000027': ['Mobile App Design Essentials', '2019'], '1000000028': ['Systems Architecture: An Overview', '2020'], '1000000029': ['Advanced Topics in Python Programming', '2021'], '1000000030': ['The Future of Technology: Trends and Predictions', '2018']}\n"
     ]
    }
   ],
   "source": [
    "# Books.csv each books ISBN has a title and publication year tied to them\n",
    "# isbn,title,publication_year\n",
    "# 1000000001,Data Structures in Python,2020\n",
    "\n",
    "# Rating.csv, each ISBN number has a list of ratings tied to them\n",
    "# book_isbn,rating_list\n",
    "# 1000000001,\"[4, 1, 4, 2, 1, 3, 4, 3, 1, 2]\"\n",
    "\n",
    "# Authors.csv, each Author has a list of ISBN for books tied to them\n",
    "# John Doe,Jane Smith,Emily \n",
    "# \"['1000000001', '1000000014', '1000000027']\",\"['1000000002', '1000000015']\"\n",
    "\n",
    "\n",
    "# books_Complete = {}\n",
    "# books_complete[books.isbn] = [books.title, books.publication_year, authors.author, rating.ratinglist]\n",
    "\n",
    "\n",
    "\n",
    "# Dictionary to store the combined information\n",
    "books_complete = {}\n",
    "\n",
    "# Paths to your CSV files\n",
    "books_path = 'Bronze/books.csv'\n",
    "rating_path = 'Bronze/book_ratings.csv'\n",
    "authors_path = 'Bronze/authors.csv'\n",
    "\n",
    "# Read data from Books.csv\n",
    "with open(books_path, 'r') as books_file:\n",
    "    books_reader = csv.DictReader(books_file)\n",
    "    for row in books_reader:\n",
    "        isbn = row['isbn']\n",
    "        title = row['title']\n",
    "        publication_year = row['publication_year']\n",
    "        books_complete[isbn] = [title, publication_year]\n",
    "\n",
    "print(books_complete)\n",
    "\n",
    "# # Read data from Authors.csv\n",
    "# with open(authors_path, 'r') as authors_file:\n",
    "#     authors_reader = csv.reader(authors_file)\n",
    "#     next(authors_reader)  # Skip the header\n",
    "#     for row in authors_reader:\n",
    "#         author_name = row[0]\n",
    "#         isbn_list = ast.literal_eval(row[1])  # Safely convert the string to a list\n",
    "#         for isbn in isbn_list:\n",
    "#             if isbn in books_complete:\n",
    "#                 books_complete[isbn].append(author_name)\n",
    "\n",
    "\n",
    "# # Read data from Rating.csv\n",
    "# with open(rating_path, 'r') as rating_file:\n",
    "#     rating_reader = csv.DictReader(rating_file)\n",
    "#     for row in rating_reader:\n",
    "#         isbn = row['book_isbn']\n",
    "#         rating_list = ast.literal_eval(row['rating_list'])  # Safely convert the string to a list\n",
    "#         if isbn in books_complete:\n",
    "#             books_complete[isbn].append(rating_list)\n",
    "\n",
    "# # Print the combined information\n",
    "# for isbn, info in books_complete.items():\n",
    "#     print(f\"ISBN: {isbn}, Title: {info[0]}, Publication Year: {info[1]}, Author: {info[2]}, Ratings: {info[3]}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Read data from Authors.csv\n",
    "# import ast\n",
    "# with open(authors_path, 'r') as authors_file:\n",
    "#     authors_reader = csv.reader(authors_file)\n",
    "#     # next(authors_reader)  # Skip the header\n",
    "#     for row in authors_reader:\n",
    "#         print(row[0])\n",
    "#         author_name = row[0]\n",
    "#         # isbn_list = ast.literal_eval(row[1])  # Safely convert the string to a list\n",
    "#         # for isbn in isbn_list:\n",
    "#         #     if isbn in books_complete:\n",
    "#         #         books_complete[isbn].append(author_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combine Data \n",
    "- Create a comprehensive dataset where each book entry includes its title, publication year, author, and its average rating.\n",
    "- Store this as a CSV in your `Silver` folder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "authors_csv_path = \"Bronze/authors.csv\"\n",
    "book_ratings_csv = \"Bronze/book_ratings.csv\"\n",
    "books_csv = \"Bronze/books.csv\"\n",
    "\n",
    "csv_list = [authors_csv_path, book_ratings_path, books_csv]\n",
    "\n",
    "\n",
    "\n",
    "def read_return_csv(path):\n",
    "    with open(path, 'r', newline='') as file:\n",
    "        csvit = csv.DictReader(file)\n",
    "        return_list = []\n",
    "        for row in csvit:\n",
    "            return_list.append(row)\n",
    "\n",
    "        return return_list\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "# with open(authors_csv_path, 'r', newline='') as author_csv_file:\n",
    "#     csv_authors = csv.reader(author_csv_file)\n",
    "#     for row in csv_authors:\n",
    "#         print(row)\n",
    "\n",
    "# with open(book_ratings_csv, 'r', newline='') as book_ratings_csv_file:\n",
    "#     csv_book_ratings = csv.reader(book_ratings_csv_file)\n",
    "#     for row in csv_book_ratings:\n",
    "#         print(row)\n",
    "\n",
    "# with open(books_csv, 'r', newline='') as book_csv_file:\n",
    "#     csv_books = csv.reader(book_csv_file)\n",
    "#     for row in csv_books:\n",
    "#         print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_list = []\n",
    "\n",
    "for i in csv_list:\n",
    "    complete_list.append(read_return_csv(i))\n",
    "\n",
    "\n",
    "author_isbn = complete_list[0]\n",
    "book_rating = complete_list[1]\n",
    "title_pub = complete_list[2]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['isbn', 'title', 'publication_year', 'rating_list', 'author'], ['1000000001', 'Data Structures in Python', '2020', '[4, 4, 3, 3, 2, 1, 4, 2, 2, 2]', 'John Doe'], ['1000000014', 'Big Data Analysis', '2021', '[3, 2, 1, 3, 3, 3, 1, 2, 1, 1]', 'John Doe'], ['1000000027', 'Mobile App Design Essentials', '2019', '[4, 3, 4, 4, 3, 4, 1, 2, 2, 3]', 'John Doe'], ['1000000002', 'Introduction to ETL Processes', '2019', '[1, 1, 1, 3, 3, 4, 4, 1, 1, 4]', 'Jane Smith'], ['1000000015', 'Programming in Java', '2018', '[4, 2, 1, 2, 3, 3, 3, 2, 2, 4]', 'Jane Smith'], ['1000000003', 'APIs for Beginners', '2021', '[3, 1, 3, 4, 2, 2, 3, 2, 4, 2]', 'Emily Johnson'], ['1000000004', 'Machine Learning Fundamentals', '2018', '[3, 4, 4, 1, 1, 2, 3, 1, 2, 2]', 'Michael Brown'], ['1000000016', 'HTML and CSS Design', '2022', '[1, 1, 3, 4, 1, 1, 4, 4, 1, 2]', 'Michael Brown'], ['1000000005', 'Database Management Essentials', '2022', '[2, 3, 4, 4, 3, 1, 3, 3, 2, 4]', 'Sarah Davis'], ['1000000006', 'Cloud Computing Basics', '2020', '[2, 3, 1, 2, 1, 3, 1, 1, 2, 3]', 'William Miller'], ['1000000017', 'Software Testing Techniques', '2019', '[2, 4, 4, 1, 1, 2, 1, 4, 3, 1]', 'William Miller'], ['1000000028', 'Systems Architecture: An Overview', '2020', '[4, 4, 2, 2, 2, 2, 1, 3, 2, 3]', 'William Miller'], ['1000000007', 'The Art of Data Science', '2019', '[4, 4, 1, 1, 2, 2, 1, 1, 4, 1]', 'Elizabeth Wilson'], ['1000000018', 'Blockchain Basics', '2020', '[1, 3, 3, 2, 2, 2, 3, 3, 3, 3]', 'Elizabeth Wilson'], ['1000000008', 'Python for Data Analysis', '2021', '[2, 1, 1, 4, 2, 3, 2, 4, 2, 3]', 'David Moore'], ['1000000009', 'Algorithms Unlocked', '2020', '[3, 3, 2, 3, 2, 3, 1, 2, 3, 1]', 'Jennifer Taylor'], ['1000000019', 'Artificial Intelligence Concepts', '2021', '[2, 1, 1, 4, 1, 4, 3, 1, 3, 1]', 'Jennifer Taylor'], ['1000000029', 'Advanced Topics in Python Programming', '2021', '[3, 2, 2, 4, 3, 4, 4, 3, 4, 3]', 'Jennifer Taylor'], ['1000000010', 'Web Development with JavaScript', '2018', '[3, 2, 2, 4, 3, 2, 2, 4, 2, 4]', 'Richard Anderson'], ['1000000011', 'Introduction to IoT', '2022', '[2, 1, 4, 3, 3, 4, 1, 1, 4, 4]', 'Patricia Jackson'], ['1000000020', 'Quantum Computing 101', '2018', '[1, 4, 3, 4, 4, 3, 2, 4, 2, 3]', 'Patricia Jackson'], ['1000000012', 'Networking for Beginners', '2019', '[1, 1, 2, 3, 2, 1, 4, 4, 2, 3]', 'Christopher Harris'], ['1000000021', 'Virtual Reality in the Modern World', '2022', '[3, 1, 1, 4, 2, 4, 2, 2, 2, 4]', 'Christopher Harris'], ['1000000030', 'The Future of Technology: Trends and Predictions', '2018', '[4, 4, 2, 3, 4, 2, 2, 3, 1, 1]', 'Christopher Harris']]\n"
     ]
    }
   ],
   "source": [
    "#LIST METHOD\n",
    "merged = [[\"isbn\", \"title\", \"publication_year\", \"rating_list\", \"author\"]]\n",
    "for author in author_isbn:\n",
    "    for book in book_rating:\n",
    "        if author[\"isbn\"] == book[\"book_isbn\"]:\n",
    "            for title in title_pub:\n",
    "                if(author[\"isbn\"] == title[\"isbn\"]):\n",
    "                    # merged[book[\"book_isbn\"]] = [title[\"title\"], title[\"publication_year\"], book[\"rating_list\"], author[\"author\"]]\n",
    "                    merged.append([book[\"book_isbn\"],title[\"title\"], title[\"publication_year\"], book[\"rating_list\"], author[\"author\"]])\n",
    "                \n",
    "print(merged)\n",
    "# for author in author_isbn:\n",
    "#     print(author)\n",
    "#     merged[author[1]] = author[0]\n",
    "\n",
    "# for i in book_rating:\n",
    "#     print(i)\n",
    "\n",
    "# for i in title_pub:\n",
    "#     print(i)\n",
    "\n",
    "# print(merged)\n",
    "\n",
    "# for lists in complete_list:\n",
    "#     for i in lists:\n",
    "#         print(i[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LIST METHOD\n",
    "merged_path = 'Silver/merged.csv'\n",
    "with open(merged_path, 'w', newline='') as csv_file_out:\n",
    "    field_names = [\"isbn\", \"Info\"]\n",
    "    csv_writer = csv.writer(csv_file_out)\n",
    "\n",
    "    # Write the header to the CSV file\n",
    "    # csv_writer.writerow(merged[0])\n",
    "\n",
    "    # # Write the rest of data to the CSV file\n",
    "    # csv_writer.writerows(merged[1:])\n",
    "    csv_writer.writerows(merged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DICT METHOD\n",
    "merged = [[\"isbn\", \"title\", \"publication_year\", \"rating_list\", \"author\"]]\n",
    "for author in author_isbn:\n",
    "    for book in book_rating:\n",
    "        if author[\"isbn\"] == book[\"book_isbn\"]:\n",
    "            for title in title_pub:\n",
    "                if(author[\"isbn\"] == title[\"isbn\"]):\n",
    "                    # merged[book[\"book_isbn\"]] = [title[\"title\"], title[\"publication_year\"], book[\"rating_list\"], author[\"author\"]]\n",
    "                    merged.append([book[\"book_isbn\"],title[\"title\"], title[\"publication_year\"], book[\"rating_list\"], author[\"author\"]])\n",
    "                \n",
    "print(merged)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.3 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
